{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d5a20-757a-401b-b283-fa188c42be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib widget\n",
    "#%matplotlib ipympl\n",
    "\n",
    "#%reload_ext tensorboard\n",
    "#%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd98c0b-5e5c-4549-98e8-d604b8b111ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle, subprocess\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.ndimage import label as scipy_label\n",
    "import torch\n",
    "import sklearn\n",
    "import csv\n",
    "import gc\n",
    "import pydicom\n",
    "import networkx as nx\n",
    "#from radiomics import featureextractor\n",
    "#import radiomics\n",
    "\n",
    "import glob\n",
    "from platipy.imaging import ImageVisualiser\n",
    "from platipy.dicom.io.rtstruct_to_nifti import convert_rtstruct, read_dicom_image\n",
    "\n",
    "from hnc_project import data_prep as dp\n",
    "#from hnc_project import myshow\n",
    "from hnc_project import graph_making as gm\n",
    "from hnc_project.pytorch import dataset_class_prototype as dc\n",
    "from hnc_project.pytorch.run_model_lightning import RunModel\n",
    "#%matplotlib notebook\n",
    "%matplotlib widget\n",
    "plt.ion()\n",
    "#import initial_ml as iml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8e2fc6-966e-4a72-b809-349a7405e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '../../data/RADCURE/'\n",
    "nii_directory = '../../data/RADCURE/Nii'\n",
    "resample_directory = '../../data/RADCURE/Nii_resample_111'\n",
    "graph_directory = '../../data/RADCURE/graph_staging'\n",
    "edge_directory = '../../data/RADCURE/edge_staging'\n",
    "patch_directory = '../../data/RADCURE/Nii_111_80_80_80_Crop'\n",
    "location_pickle = '../../data/RADCURE/Nii_111_80_80_80_Crop/locations.pkl'\n",
    "plot_directory = '../../data/RADCURE/plots'\n",
    "\n",
    "vis_dir = '../../data/RADCURE/RADCURE_vis_snapshots'\n",
    "vis_path = Path(vis_dir)\n",
    "vis_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "data_path = Path(data_directory)\n",
    "nii_path = Path(nii_directory)\n",
    "resample_path = Path(resample_directory)\n",
    "patch_path = Path(patch_directory)\n",
    "location_pickle_path = Path(location_pickle)\n",
    "plot_path = Path(plot_directory)\n",
    "graph_path = Path(graph_directory)\n",
    "edge_path = Path(edge_directory)\n",
    "\n",
    "nii_path.mkdir(exist_ok=True, parents=True)\n",
    "resample_path.mkdir(exist_ok=True, parents=True)\n",
    "patch_path.mkdir(exist_ok=True, parents=True)\n",
    "plot_path.mkdir(exist_ok=True, parents=True)\n",
    "graph_path.mkdir(exist_ok=True, parents=True)\n",
    "edge_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "meta_df = pd.read_csv(data_path.joinpath('metadata.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1020473-ce0a-4169-b09d-27ed676e393b",
   "metadata": {},
   "source": [
    "## Match RSTRUCT to CTs\n",
    "This uses the meta file to match rtstructs to CTs and drops patients without a corresponding CT or rtstruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df27f0-0295-4a78-b39e-2149cdaea2f2",
   "metadata": {},
   "source": [
    "## Convert selected pats to NifTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe22b00-7fb6-4643-a1f2-c7ea52f4f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = []\n",
    "for pat, df_group in tqdm(meta_df.groupby(\"Subject ID\")):\n",
    "\n",
    "    # Select the structure set with the later date\n",
    "    longest_len = None\n",
    "    latest_file = None\n",
    "    linked_ct_uid = None\n",
    "    #print(f\"{pat}\")\n",
    "    for idx, rtstruct_row in df_group[df_group.Modality == \"RTSTRUCT\"].iterrows():\n",
    "        rtstruct_dir = data_path.joinpath(rtstruct_row[\"File Location\"].replace('\\\\','/'))\n",
    "        #print(rtstruct_dir)\n",
    "        rtstruct_file = list(rtstruct_dir.glob(\"*\"))[0]\n",
    "        rtstruct = pydicom.read_file(rtstruct_file)\n",
    "        try:\n",
    "            rtstruct_len = len(rtstruct.StructureSetROISequence)\n",
    "        except:\n",
    "            print(f'{pat}, RTStruct ROI Sequence is empty')\n",
    "            rstruct_len = 0\n",
    "        #print(f\"    {rtstruct_len}\")\n",
    "        if longest_len is None or rtstruct_len > longest_len:\n",
    "            longest_len = rtstruct_len\n",
    "            if longest_len != 0:\n",
    "                latest_file = idx\n",
    "                linked_ct_uid = rtstruct.ReferencedFrameOfReferenceSequence[0].RTReferencedStudySequence[0].RTReferencedSeriesSequence[0].SeriesInstanceUID\n",
    "    #print(f\"    Chosen file: {latest_file} with len: {longest_len}\") \n",
    "    # Select the RTSTRUCT for this patient\n",
    "    if latest_file is None:\n",
    "        print(f\"{pat} has no relevant RTStruct\")\n",
    "        continue\n",
    "    selected_rows.append(latest_file)\n",
    "    \n",
    "    # Also select the CT image linked to the RTSTRUCT\n",
    "    try: \n",
    "        ct_idx = meta_df[meta_df[\"Series UID\"] == linked_ct_uid].iloc[0].name\n",
    "        selected_rows.append(ct_idx)\n",
    "    except:\n",
    "        print(f\"{pat} does not have linked CT or RTStruct\")\n",
    "meta_df_clean = meta_df.loc[selected_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeb9507-420b-44f9-99a4-f8cf295d4560",
   "metadata": {},
   "outputs": [],
   "source": [
    "checks = [\n",
    "          'gtv',\n",
    "         ]\n",
    "for patient, pat_df in tqdm(meta_df_clean.groupby(\"Subject ID\")):\n",
    "    \n",
    "    patient_nii_path = nii_path.joinpath(patient)\n",
    "    patient_nii_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    #Convert the CT Image\n",
    "    ct_row = pat_df[pat_df[\"Modality\"] == \"CT\"].iloc[0]\n",
    "    ct_directory = data_path.joinpath(ct_row[\"File Location\"].replace('\\\\','/'))\n",
    "    ct_image = read_dicom_image(ct_directory)\n",
    "    output_file = patient_nii_path.joinpath(\"image.nii.gz\")\n",
    "    sitk.WriteImage(ct_image, str(output_file))\n",
    "  \n",
    "    # Convert the Structures\n",
    "    rtstruct_row = pat_df[pat_df[\"Modality\"] == \"RTSTRUCT\"].iloc[0]\n",
    "    rtstruct_dir = data_path.joinpath(rtstruct_row[\"File Location\"].replace('\\\\','/'))\n",
    "    rtstruct_file = list(rtstruct_dir.glob(\"*\"))[0]\n",
    "    try:\n",
    "        convert_rtstruct(ct_directory, rtstruct_file, output_dir=patient_nii_path)\n",
    "    except:\n",
    "        print(f\"failed: {patient}\")\n",
    "        continue\n",
    "  \n",
    "    # Prepare and save the visualisation\n",
    "    if not np.any(['gtv' in str(s).lower() for s in patient_nii_path.glob(\"Struct_*.nii.gz\")]):\n",
    "        print(f\"failed to visualize: {patient}\")\n",
    "        \n",
    "    #vis = ImageVisualiser(ct_image)\n",
    "    #\n",
    "    #contours = {s.name.split(\".\")[0].replace(\"Struct_\", \"\"): sitk.ReadImage(str(s)) for s in patient_nii_path.glob(\"Struct_*.nii.gz\") if np.any([n in str(s).lower() for n in checks])}\n",
    "    #vis.add_contour(contours)\n",
    "    #try:\n",
    "    #    fig = vis.show()\n",
    "    #except:\n",
    "    #    print(f\"failed to visualize: {patient}\")\n",
    "    #output_file_path = vis_path.joinpath(f\"{patient}_vis.png\")\n",
    "    #fig.savefig(output_file_path, dpi=fig.dpi)\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba319c5-d689-420d-b7bb-104c774d5ead",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## list of patients to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bdf814-29f0-49e2-99f1-7582c7d46173",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_to_remove = [\n",
    "'RADCURE-0012',\n",
    "'RADCURE-0046',\n",
    "'RADCURE-0055',\n",
    "'RADCURE-0082',\n",
    "'RADCURE-0087',\n",
    "'RADCURE-0430',\n",
    "'RADCURE-0757',\n",
    "'RADCURE-0776',\n",
    "'RADCURE-0781',\n",
    "'RADCURE-0821',\n",
    "'RADCURE-0923',\n",
    "'RADCURE-1011',\n",
    "'RADCURE-1084',\n",
    "'RADCURE-1206',\n",
    "'RADCURE-1230',\n",
    "'RADCURE-1246',\n",
    "'RADCURE-1330',\n",
    "'RADCURE-1364',\n",
    "'RADCURE-1432',\n",
    "'RADCURE-1463',\n",
    "'RADCURE-1493',\n",
    "'RADCURE-1532',\n",
    "'RADCURE-1576',\n",
    "'RADCURE-1582',\n",
    "'RADCURE-1810',\n",
    "'RADCURE-1814',\n",
    "'RADCURE-1873',\n",
    "'RADCURE-1983',\n",
    "'RADCURE-1985',\n",
    "'RADCURE-2006',\n",
    "'RADCURE-2011',\n",
    "'RADCURE-2069',\n",
    "'RADCURE-2070',\n",
    "'RADCURE-2071',\n",
    "'RADCURE-2124',\n",
    "'RADCURE-2214',\n",
    "'RADCURE-2216',\n",
    "'RADCURE-2258',\n",
    "'RADCURE-2273',\n",
    "'RADCURE-2275',\n",
    "'RADCURE-2288',\n",
    "'RADCURE-2295',\n",
    "'RADCURE-2306',\n",
    "'RADCURE-2372',\n",
    "'RADCURE-2695',\n",
    "'RADCURE-2789',\n",
    "'RADCURE-2790',\n",
    "'RADCURE-2809',\n",
    "'RADCURE-2854',\n",
    "'RADCURE-2860',\n",
    "'RADCURE-2869',\n",
    "'RADCURE-2995',\n",
    "'RADCURE-3077',\n",
    "'RADCURE-3418',\n",
    "'RADCURE-3476',\n",
    "'RADCURE-3528',\n",
    "'RADCURE-3585',\n",
    "'RADCURE-3636',\n",
    "'RADCURE-3710',\n",
    "'RADCURE-3733',\n",
    "'RADCURE-3747',\n",
    "'RADCURE-3834',\n",
    "'RADCURE-3849',\n",
    "'RADCURE-3916',\n",
    "'RADCURE-3926',\n",
    "'RADCURE-3933',\n",
    "'RADCURE-4090',\n",
    "'RADCURE-4117',\n",
    "'RADCURE-4130',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf00e36-6303-4b22-9e35-af74de54fc3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Remove extraneous masks and patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf9e946-9013-47e1-b8c9-473ca85bae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmdir(directory):\n",
    "    directory = Path(directory)\n",
    "    for item in directory.iterdir():\n",
    "        if item.is_dir():\n",
    "            rmdir(item)\n",
    "        else:\n",
    "            item.unlink()\n",
    "    directory.rmdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1514ed-d9e5-410b-ae04-a002c12bf752",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pat in tqdm(list(nii_path.glob('*'))):\n",
    "    pat_str = pat.as_posix().split('/')[-1]\n",
    "    print(pat_str)\n",
    "    if pat_str in patients_to_remove:\n",
    "        print(f'    {pat} is missing GTVs, removing corresponding directory')\n",
    "        rmdir(pat)    \n",
    "        continue\n",
    "    print(f'    GTV structures present:')\n",
    "    for m in pat.glob('*.nii.gz'):\n",
    "        list_m = list(pat.glob('*.nii.gz'))\n",
    "        if 'image' in str(m):\n",
    "            continue\n",
    "        elif 'gtv' not in str(m).lower():\n",
    "            m.unlink()\n",
    "        else:\n",
    "            print(f'        {m.as_posix().split(\"/\")[-1].replace(\".nii.gz\",\"\")}')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8714e-d2eb-47a6-80ec-7be9297f6d05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Resampling code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd91361-456c-48b1-b4ce-206bfa00bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler = sitk.ResampleImageFilter()\n",
    "resampler.SetOutputDirection([1, 0, 0, 0, 1, 0, 0, 0, 1])\n",
    "resampling = [1,1,1]\n",
    "resampler.SetOutputSpacing(resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93441f56-0273-44ef-bd0c-03e62ed3b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bouding_boxes(ct, pt):\n",
    "    \"\"\"\n",
    "    Get the bounding boxes of the CT and PT images.\n",
    "    This works since all images have the same direction\n",
    "    \"\"\"\n",
    "\n",
    "    ct_origin = np.array(ct.GetOrigin())\n",
    "    pt_origin = np.array(pt.GetOrigin())\n",
    "\n",
    "    ct_position_max = ct_origin + np.array(ct.GetSize()) * np.array(\n",
    "        ct.GetSpacing())\n",
    "    pt_position_max = pt_origin + np.array(pt.GetSize()) * np.array(\n",
    "        pt.GetSpacing())\n",
    "    return np.concatenate(\n",
    "        [\n",
    "            np.maximum(ct_origin, pt_origin),\n",
    "            np.minimum(ct_position_max, pt_position_max),\n",
    "        ],\n",
    "        axis=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4783ae7-4109-4445-96e6-fdfb4f46c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_one_patient(p):\n",
    "    pat_str = p.as_posix().split('/')[-1]\n",
    "    patient_resample_path = resample_path.joinpath(pat_str)\n",
    "    patient_resample_path.mkdir(exist_ok=True, parents=True)\n",
    "    try:\n",
    "        ct = sitk.ReadImage(p.joinpath('image.nii.gz').as_posix())\n",
    "    except:\n",
    "        print(f\"    unable to read image file for {pat_str}\")\n",
    "        #os.rmdir(p)\n",
    "        #os.rmdir(patient_resample_path)\n",
    "        #print(f\"{pat_str} folder removed due to being empty\")\n",
    "        return\n",
    "    #label = sitk.ReadImage(os.path.join(savePath, p, 'mask_GTVp.nii.gz'))\n",
    "    bb = get_bouding_boxes(ct, ct)\n",
    "    size = np.round((bb[3:] - bb[:3]) / resampling).astype(int)\n",
    "    resampler.SetOutputOrigin(bb[:3])\n",
    "    resampler.SetSize([int(k) for k in size])  # sitk is so stupid\n",
    "    resampler.SetInterpolator(sitk.sitkBSpline)\n",
    "    ct = resampler.Execute(ct)\n",
    "\n",
    "    #sitk.WriteImage(ct, patient_resample_path.joinpath('image.nii.gz').as_posix())\n",
    "    resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "\n",
    "    mask_sizes = []\n",
    "    for m in p.glob('*.nii.gz'):\n",
    "        if 'image' in str(m): continue\n",
    "        label = sitk.ReadImage(m.as_posix())\n",
    "        label = resampler.Execute(label)\n",
    "\n",
    "        label_array = sitk.GetArrayViewFromImage(label)\n",
    "        label_locations = np.where(label_array > 0)\n",
    "        mask_sizes.append(np.max(label_locations, axis=1) - np.min(label_locations, axis=1))\n",
    "        #sitk.WriteImage(label, patient_resample_path.joinpath(m.as_posix().split('/')[-1]).as_posix())\n",
    "    return mask_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a2a1c7-28fa-485c-99c7-df3d19a4140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_sizes = [[0,0,0]]\n",
    "for pat in tqdm(list(nii_path.glob('*'))):\n",
    "    pat_str = pat.as_posix().split('/')[-1]\n",
    "    #print(f\"{pat_str}\")\n",
    "    #if pat_str in patients_to_drop: continue   \n",
    "    t_size = resample_one_patient(pat)\n",
    "    tumor_sizes.extend(t_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cded099-a2c2-473c-82b8-78a97e3f730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path.joinpath('tumor_sizes.pkl'), 'wb') as f:\n",
    "    pickle.dump(tumor_sizes, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a28bc69-49c4-4696-80c6-a8b055eeea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tumor_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46c031-9241-4eca-8884-62f373c831bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_sizes = pd.read_pickle(data_path.joinpath('tumor_sizes.pkl'))\n",
    "tumor_sizes = np.array(tumor_sizes)\n",
    "#tumor_sizes = np.delete(tumor_sizes, (0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f89d9-8d49-4c4c-bd86-4bf0649d194f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73307d54-bbea-4e4a-a8f2-7452ab1927b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### tumor_sizes_dict = {}\n",
    "idx = 0\n",
    "for pat in tqdm(list(nii_path.glob('*'))):\n",
    "    pat_str = pat.as_posix().split('/')[-1]\n",
    "    for m in pat.glob('*.nii.gz'):\n",
    "        if 'image' in str(m): \n",
    "            continue\n",
    "        m_str = m.as_posix().split('/')[-1].strip('.nii.gz').strip('Struct_')\n",
    "        tumor_sizes_dict[f\"{pat_str}_{m_str}\"] = tumor_sizes[idx]\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0891affa-e696-4fc4-8346-2a4e8c3e8db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_sizes_df = pd.DataFrame(tumor_sizes_dict.values(), columns=['z', 'y', 'x'], index=tumor_sizes_dict.keys())\n",
    "print(tumor_sizes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98617617-7912-4846-9c13-71cea331b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tumor_sizes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d24f6c-bf76-42f9-a651-94acff788ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_sizes_df[['GTVp' in pat for pat in tumor_sizes_df.index]].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de93821-95a6-470e-8393-1641708ae903",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_sizes_df[['3746' in pat for pat in tumor_sizes_df.index]] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba1bde-affc-4859-a6ce-8a1972f64dea",
   "metadata": {},
   "source": [
    "## 4. Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3826a6fd-7c9e-466a-88db-d53280b7b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid(mask, p):\n",
    "\n",
    "    stats = sitk.LabelShapeStatisticsImageFilter()\n",
    "    stats.Execute(mask)\n",
    "    try:\n",
    "        centroid_coords = stats.GetCentroid(1)\n",
    "    except:\n",
    "        print(f'Something is wrong with centroid calculation for patient: {p}')\n",
    "    centroid_idx = mask.TransformPhysicalPointToIndex(centroid_coords)\n",
    "\n",
    "    return np.asarray(centroid_idx, dtype=np.float64), np.asarray(centroid_coords, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c8089-000f-415e-86b6-638e3dd46609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_range(min_d, max_d, d, size_d, p):\n",
    "    min_pad = 0\n",
    "    max_pad = 0\n",
    "    if min_d<0:\n",
    "        min_pad = abs(min_d)\n",
    "        min_d = 0\n",
    "        #max_d = min_d + d\n",
    "        #if max_d - size_d > 0:\n",
    "        #    max_pad = max_d-size_d\n",
    "            \n",
    "        #assert (max_d<size_d), f\"Cannot extract the patch with the shape {size_d} from the image with the shape {d} for patient {p}.\"\n",
    "    \n",
    "    if max_d>d:\n",
    "        max_pad = max_d - d\n",
    "        max_d = d\n",
    "        #min_d = max_d - size_d\n",
    "        #if min_d < 0:\n",
    "        #    min_pad = abs(min_d)\n",
    "            \n",
    "        #assert (min_d>0), f\"Cannot extract the patch with the shape {size_d} from the image with the shape {d} for patient {p}.\"\n",
    "\n",
    "    return min_d, max_d, int(min_pad), int(max_pad)\n",
    "patients_to_retry = [\n",
    "    'HNSCC-01-0225',\n",
    "    'HNSCC-01-0259',\n",
    "    'HNSCC-01-0272',\n",
    "    'HNSCC-01-0434',\n",
    "]\n",
    "physical_locations = {}\n",
    "for p_dir in tqdm(list(resample_path.glob('*'))):\n",
    "    p_str = p_dir.as_posix().split('/')[-1]\n",
    "    print(p_str)\n",
    "    #if p_str not in patients_to_retry: continue\n",
    "    #try:\n",
    "    #if p_str in patients_to_drop:\n",
    "    #    print('skip ', p_str)\n",
    "    #    continue\n",
    "    patient_patch_path = patch_path.joinpath(p_str)\n",
    "    patient_patch_path.mkdir(exist_ok=True, parents=True)\n",
    "    physical_locations[p_str] = {}\n",
    "    patch_size = np.array([80,80,80])\n",
    "    for m in p_dir.glob('*.nii.gz'):\n",
    "        print('-----------------')\n",
    "        m_str = m.as_posix().split('/')[-1]\n",
    "        if 'image' in m_str: continue\n",
    "        #try:\n",
    "        image = sitk.ReadImage(p_dir.joinpath('image.nii.gz').as_posix())\n",
    "        mask = sitk.ReadImage(m.as_posix())\n",
    "        print(m_str)\n",
    "        #crop the image to patch_size around the tumor center\n",
    "        tumour_center, center_location = find_centroid(mask, p_str) # center of GTV\n",
    "        size = patch_size\n",
    "        min_coords = np.floor(tumour_center - size / 2).astype(np.int64)\n",
    "        max_coords = np.floor(tumour_center + size / 2).astype(np.int64)\n",
    "        min_x, min_y, min_z = min_coords\n",
    "        max_x, max_y, max_z = max_coords\n",
    "        (img_x, img_y, img_z)=image.GetSize()\n",
    "        min_x, max_x, min_pad_x, max_pad_x = tune_range(min_x, max_x, img_x, size[0], p_str) \n",
    "        min_y, max_y, min_pad_y, max_pad_y = tune_range(min_y, max_y, img_y, size[1], p_str) \n",
    "        min_z, max_z, min_pad_z, max_pad_z = tune_range(min_z, max_z, img_z, size[2], p_str) \n",
    "\n",
    "        min_pad = int(max([min_pad_x, min_pad_y, min_pad_z]))\n",
    "        max_pad = int(max([max_pad_x, max_pad_y, max_pad_z]))\n",
    "        lpad = list([min_pad_x, min_pad_y, min_pad_z])\n",
    "        upad = list([max_pad_x, max_pad_y, max_pad_z])\n",
    "        #print(m_str)\n",
    "        #print(lpad)\n",
    "        #print(upad)\n",
    "        print(image.GetSize())\n",
    "        print(min_coords, max_coords)\n",
    "        print(min_pad, max_pad)\n",
    "        image = image[min_x:max_x, min_y:max_y, min_z:max_z]\n",
    "        # window image intensities to [-500, 1000] HU range\n",
    "        image = sitk.Clamp(image, sitk.sitkFloat32, -500, 500)\n",
    "        mask = mask[min_x:max_x, min_y:max_y, min_z:max_z]\n",
    "        print(image.GetSize())\n",
    "        image = sitk.ConstantPad(image, lpad, upad, 0.0)\n",
    "        mask = sitk.ConstantPad(mask, lpad, upad, 0.0)\n",
    "        print(image.GetSize())\n",
    "        sitk.WriteImage(image, patient_patch_path.joinpath(f\"image_{m_str.replace('Struct_','')}\").as_posix())\n",
    "        sitk.WriteImage(mask, patient_patch_path.joinpath(m_str).as_posix())\n",
    "        physical_locations[p_str][m_str.replace('Struct_','').replace('.nii.gz','')] = center_location\n",
    "        del(image)\n",
    "        del(mask)\n",
    "        #except:\n",
    "        #    print(m)\n",
    "        #    raise Exception('something went wrong...')\n",
    "    \n",
    "    #except:\n",
    "    #    print(p_str)\n",
    "        \n",
    "with open(patch_path.joinpath('locations.pkl'), 'wb') as f:\n",
    "    pickle.dump(physical_locations, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60cb62c-94f5-42b3-8d7f-31a1bd1287b0",
   "metadata": {},
   "source": [
    "## Graph Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6f191-9cf9-4f44-ae9d-240cc1943c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_patch_paths = patch_path.glob('*/')\n",
    "tumor_locations = pd.read_pickle(location_pickle_path)\n",
    "centered_locations = {}\n",
    "no_gtvp = []\n",
    "for pat in tqdm(patient_patch_paths):\n",
    "    pat_str = pat.as_posix().split('/')[-1]\n",
    "    if 'locations' in pat_str: continue\n",
    "    if 'no_gtvp' in pat_str: continue\n",
    "    print(pat_str)\n",
    "    centered_locations[pat_str] = {}\n",
    "    n_tumors = len(tumor_locations[pat_str])\n",
    "    translation_factor = np.array([0., 0., 0.])\n",
    "    if n_tumors == 1:\n",
    "        if 'GTVp' in tumor_locations[pat_str].keys():\n",
    "            centered_locations[pat_str]['GTVp'] = np.array([0., 0., 0.])\n",
    "        else:\n",
    "            centered_locations[pat_str][next(iter(tumor_locations[pat_str].keys()))] = np.array([0., 0., 0.])\n",
    "            no_gtvp.append(pat_str)\n",
    "        continue\n",
    "    else:\n",
    "        gtvs = tumor_locations[pat_str].keys()\n",
    "        print(f\"    {tumor_locations[pat_str].keys()}\")\n",
    "        if 'GTVp' in tumor_locations[pat_str].keys():\n",
    "            translation_factor = tumor_locations[pat_str]['GTVp']\n",
    "        else:\n",
    "            no_gtvp.append(pat_str)\n",
    "            print('    no GTVp, choosing highest GTVn in Z')\n",
    "            array_locs = np.array([val for val in tumor_locations[pat_str].values()])\n",
    "            origin_idx = np.where(array_locs == np.max(array_locs, axis=0)[2])[0][0]\n",
    "            translation_factor = array_locs[origin_idx]\n",
    "    for tumor in tumor_locations[pat_str]:\n",
    "        centered_locations[pat_str][tumor.replace('.nii.gz','')] = tumor_locations[pat_str][tumor] - translation_factor\n",
    "\n",
    "with open(edge_path.joinpath('centered_locations_radcure_100324.pkl'), 'wb') as f:\n",
    "    pickle.dump(centered_locations, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e830f-8da0-403c-beaf-f3d4537cc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(patch_path.joinpath('patients_with_no_gtvp.pkl'), 'wb') as f:\n",
    "    pickle.dump(no_gtvp, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37780c10-f793-4a45-8b94-3cb151b3bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = sqrt(x^2 + y^2 + z^2)\n",
    "# theta = atan2 ( sqrt(x^2+y^2) / z) accounting for different quadrants (make sure to use atan2 not atan)\n",
    "# phi = atan2 (y/x) \n",
    "\n",
    "spherical_locations = {}\n",
    "for pat, locs in centered_locations.items():\n",
    "    spherical_locations[pat] = {}\n",
    "    for gtv, l in locs.items():\n",
    "        if np.all([not(l[0]), not(l[1]), not(l[2])]): \n",
    "            #print(f'origin: {pat}, {gtv}')\n",
    "            spherical_locations[pat][gtv] = np.array([0.,0.,0.])\n",
    "            continue\n",
    "        radius = np.sqrt(l[0]**2+l[1]**2+l[2]**2)\n",
    "        theta = np.arctan2(np.sqrt(l[0]**2+l[1]**2), l[2])\n",
    "        phi = np.arctan2(l[1], l[0])\n",
    "        if phi < 0 and abs(phi) > np.pi/2:\n",
    "            phi = phi + 2*np.pi\n",
    "        spherical_locations[pat][gtv] = np.array([radius, theta, phi])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a05b5-b44f-4f71-95fc-1b04623f8438",
   "metadata": {},
   "source": [
    "look into once starting training:\n",
    "Make the CTs into an object containing vertex objects that store position/volume information. Within this object you then loop through all nodes and find possible nearby connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15047284-db13-4109-b41b-b2e4b28d4a20",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_edges = {}\n",
    "for pat in tqdm(spherical_locations.keys()):\n",
    "    #if '0628' not in pat: continue\n",
    "    #patient_plot_path = plot_path.joinpath(pat)\n",
    "    #patient_plot_path.mkdir(exist_ok=True, parents=True)\n",
    "    print(f\"Processing patient: {pat}\")\n",
    "    pat_locs = spherical_locations[pat]\n",
    "    if len(pat_locs) == 1:\n",
    "        print(\"    one node, empty edge array\")\n",
    "        dict_edges[pat] = []\n",
    "        continue\n",
    "    df_pat, primary = gm.make_loc_df(pat_locs)\n",
    "    if len(pat_locs) == 2 and len(df_pat) == 1:\n",
    "        print(\"    two nodes, single edge entry\")\n",
    "        print(f\"edge: [{primary.index[0]}, {df_pat.index[0]}]\")\n",
    "        dict_edges[pat] = [[primary.index[0], df_pat.index[0]]]\n",
    "        continue\n",
    "    clust_model = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
    "    clust_model = clust_model.fit(df_pat[['x', 'y', 'z']])\n",
    "    node_tree = gm.create_node_tree(clust_model.children_, df_pat)\n",
    "    connections = gm.create_connection_tree(node_tree)\n",
    "    print(connections)\n",
    "    edges = gm.make_edges(connections, df_pat, primary.index[0])\n",
    "    dict_edges[pat] = edges\n",
    "    print(edges)\n",
    "    \n",
    "    #plt.ion()\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    points = []\n",
    "    label = []\n",
    "    for gtv in df_pat.index:\n",
    "        points.append([df_pat.loc[gtv]['x'], df_pat.loc[gtv]['y'], df_pat.loc[gtv]['z']])\n",
    "        label.append(gtv)\n",
    "    for gtv in primary.index:\n",
    "        points.append([primary.loc[gtv]['x'], primary.loc[gtv]['y'], primary.loc[gtv]['z']])\n",
    "        label.append(gtv)\n",
    "        \n",
    "    points = np.array(points)\n",
    "    ax.scatter(points[:,0], points[:,1], points[:,2])\n",
    "    for i, l in enumerate(label):\n",
    "        ax.text(points[i, 0], points[i, 1], points[i, 2], l)\n",
    "    \n",
    "    edge_points = []\n",
    "    for e in edges:\n",
    "        edge_points.append([points[label.index(e[0])], points[label.index(e[1])]])\n",
    "    \n",
    "    for e in edge_points:\n",
    "        ex_diff = e[1][0] - e[0][0]\n",
    "        ey_diff = e[1][1] - e[0][1]\n",
    "        ez_diff = e[1][2] - e[0][2]\n",
    "        ax.quiver(e[0][0], e[0][1], e[0][2], ex_diff, ey_diff, ez_diff, color='r')\n",
    "    plt.savefig(plot_path.joinpath(f'connections_3D_{pat}.pdf'))\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a85ca-bde1-4d2e-904d-5d8d2d354d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(edge_path.joinpath('edges_radcure_053024.pkl'), 'wb') as f:\n",
    "    pickle.dump(dict_edges, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dfcaa3-a9f3-459f-a65c-182dcdd3f5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_list = [pat.as_posix().split('/')[-1] for pat in patch_path.glob('*/')]\n",
    "for p in patient_list:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd40278-10d2-4369-a73c-849c1da1b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(patient_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866ca89-18a5-43b2-9d7a-cfbccdbc0ec3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## New Edge creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e36646e-b9b0-4c07-a19f-e3b64c647fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_patch_paths = patch_path.glob('*/')\n",
    "tumor_locations = pd.read_pickle(location_pickle_path)\n",
    "centered_locations = {}\n",
    "no_gtvp = []\n",
    "for pat in tqdm(patient_patch_paths):\n",
    "    pat_str = pat.as_posix().split('/')[-1]\n",
    "    if 'locations' in pat_str: continue\n",
    "    if 'no_gtvp' in pat_str: continue\n",
    "    print(pat_str)\n",
    "    centered_locations[pat_str] = {}\n",
    "    n_tumors = len(tumor_locations[pat_str])\n",
    "    translation_factor = np.array([0., 0., 0.])\n",
    "    if n_tumors == 1:\n",
    "        if 'GTVp' in tumor_locations[pat_str].keys():\n",
    "            centered_locations[pat_str]['GTVp'] = np.array([0., 0., 0.])\n",
    "        else:\n",
    "            centered_locations[pat_str][next(iter(tumor_locations[pat_str].keys()))] = np.array([0., 0., 0.])\n",
    "            no_gtvp.append(pat_str)\n",
    "        continue\n",
    "    else:\n",
    "        gtvs = tumor_locations[pat_str].keys()\n",
    "        print(f\"    {tumor_locations[pat_str].keys()}\")\n",
    "        if 'GTVp' in tumor_locations[pat_str].keys():\n",
    "            translation_factor = tumor_locations[pat_str]['GTVp']\n",
    "        else:\n",
    "            no_gtvp.append(pat_str)\n",
    "            print('    no GTVp, choosing highest GTVn in Z')\n",
    "            array_locs = np.array([val for val in tumor_locations[pat_str].values()])\n",
    "            origin_idx = np.where(array_locs == np.max(array_locs, axis=0)[2])[0][0]\n",
    "            translation_factor = array_locs[origin_idx]\n",
    "    for tumor in tumor_locations[pat_str]:\n",
    "        centered_locations[pat_str][tumor.replace('.nii.gz','')] = tumor_locations[pat_str][tumor] - translation_factor\n",
    "\n",
    "#with open(edge_path.joinpath('centered_locations_radcure_100324.pkl'), 'wb') as f:\n",
    "#    pickle.dump(centered_locations, f)\n",
    "#    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5283940-8880-4c17-84bb-3b6a8b3f5102",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_graphs = {}\n",
    "edge_dict = {}\n",
    "for pat in centered_locations.keys():\n",
    "    patient_graphs[pat] = nx.DiGraph(directed=True)\n",
    "    edges_for_nx = []\n",
    "    nodes = list(centered_locations[pat].keys())\n",
    "    node_pos = list(centered_locations[pat].values())\n",
    "    n_nodes = len(nodes)\n",
    "    if n_nodes < 2:\n",
    "        edges_for_nx.extend([(nodes[0], nodes[0])])\n",
    "    else:\n",
    "        n_neighbors = n_nodes-1 if n_nodes <= 3 else 3\n",
    "        edge_list = sklearn.neighbors.kneighbors_graph(node_pos, n_neighbors).toarray()\n",
    "        for node_idx, node_name in enumerate(nodes):\n",
    "            #edges_for_nx.extend([(nodes[node_idx], nodes[jdx]) for jdx in range(len(edge_list[node_idx])) if edge_list[node_idx][jdx]])\n",
    "            edges_for_nx.extend([(nodes[node_idx], nodes[jdx]) for jdx in range(len(edge_list[node_idx]))])\n",
    "\n",
    "    patient_graphs[pat].add_edges_from(edges_for_nx)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a40157-57c2-4adf-8acd-04aec2b71313",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_graphs['RADCURE-0006'].edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b45ce-b84d-429e-81d6-7eaadf359cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(edge_path.joinpath('proto_complete_graphs_100424.pkl'), 'wb') as f:\n",
    "    pickle.dump(patient_graphs, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600520ce-4e18-4ef7-9072-68e625b0bc0c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Basic radiomic feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a96adce-7c38-4b5c-a31b-4d0b8c083eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172f9f1-b999-42d3-ae68-09d520f8bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_dict = {}\n",
    "for pat in tqdm(list(nii_path.glob('*'))):\n",
    "    pat_str = pat.as_posix().split('/')[-1]\n",
    "    for m in pat.glob('*.nii.gz'):\n",
    "        if 'image' in str(m):\n",
    "            continue\n",
    "        m_str = m.as_posix().split('/')[-1].strip('.nii.gz').strip('Struct_')\n",
    "        key_name = f\"{pat_str}__{m_str}\"\n",
    "        rad_dict[key_name] = {}\n",
    "        rad_dict[key_name]['Image'] = m.as_posix().replace(m.as_posix().split('/')[-1], 'image.nii.gz')\n",
    "        rad_dict[key_name]['Mask'] = m.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60b9184-f09a-4f14-a04b-f0f543e09b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_df = pd.DataFrame.from_dict(rad_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f24b73-147c-48d6-99e2-c3bf53ca1e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(range(0,16000, 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b491c9a4-559b-4a49-8ae8-8fbb19c312e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_df.iloc[15000:16000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612a71d3-faef-4398-896a-2dc52ad87bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca48e3-bb58-4b5c-8dfc-823d959396b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "for idx in range(8000, 9000, 1000):\n",
    "    rad_df.iloc[idx:idx+1000].to_csv(data_path.joinpath('proto_radiomics.csv'))\n",
    "    command = [\n",
    "        \"pyradiomics\",\n",
    "        data_path.joinpath('proto_radiomics.csv').as_posix(),\n",
    "        \"-o\", data_path.joinpath(f\"radiomics_part_{idx}.csv\").as_posix(),\n",
    "        \"-f\", \"csv\",\n",
    "        \"--param\", './hnc_project/radiomics/pyradiomics_param.yaml',\n",
    "    ]\n",
    "    subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94959813-ac91-4647-befb-54c5fffcb735",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a9bd6-2bbc-4a5c-89d9-aac9fef5cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "radiomics.setVerbosity(20)\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "extractor.enableImageTypeByName('Wavelet')\n",
    "print(extractor.settings)\n",
    "print(extractor.enabledImagetypes)\n",
    "print(extractor.enabledFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195722a0-ca76-4c91-a87d-3e3a862f519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_patch_paths = patch_path.glob('*/')\n",
    "for pat in patient_patch_paths:\n",
    "    pat_str = pat.as_posix().split('/')[-1]\n",
    "    print(pat_str)\n",
    "\n",
    "    patches = pat.glob('image*.nii.gz')\n",
    "    features_to_keep = {}\n",
    "    for p in patches:\n",
    "        p_name = p.as_posix().split('_')[-1].replace('.nii.gz','')\n",
    "        print(f\"    {p_name}\")\n",
    "        image = p.as_posix()\n",
    "        mask = p.as_posix().replace('image', 'Struct')\n",
    "        features = extractor.execute(image, mask)\n",
    "        features_to_keep[p_name] = {key: value for key, value in features.items() if key.startswith('original')}\n",
    "        \n",
    "    with open(radiomics_path.joinpath(f\"features_{pat_str}.pkl\"), 'wb') as f:\n",
    "        pickle.dump(features_to_keep, f)        \n",
    "        f.close()\n",
    "      \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbfb4ad-08b6-4813-b35e-331d848bd8d7",
   "metadata": {},
   "source": [
    "## testing dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc12427-baae-45d5-9035-363999b57259",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404f719-2ad4-454a-8fd4-82611c7baf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hnc_project.pytorch.gen_params_torch_cfg import model_config\n",
    "test_model = RunModel(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e41a3-e4cd-4897-9fd3-c04e94e37da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dc.DatasetGeneratorImage(test_model.config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu_v2",
   "language": "python",
   "name": "pytorch_gpu_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
