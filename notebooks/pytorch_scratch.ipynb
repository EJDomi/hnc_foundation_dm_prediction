{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d8289d-b45d-4385-8798-5e9c7cf78f83",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Scratch space for trying things out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb6a41-f65b-422a-8937-6574bd89932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib widget\n",
    "#%matplotlib ipympl\n",
    "\n",
    "#%reload_ext tensorboard\n",
    "#%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4b7199-b10e-4f05-aed5-5187e91ed955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from collections import OrderedDict\n",
    "import SimpleITK as sitk\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm.auto import tqdm\n",
    "import pickle, subprocess\n",
    "import scipy\n",
    "import sklearn\n",
    "import csv\n",
    "\n",
    "import torchmetrics\n",
    "import glob\n",
    "\n",
    "from hnc_project import data_prep as dp\n",
    "from hnc_project import myshow\n",
    "\n",
    "#%matplotlib notebook\n",
    "%matplotlib widget\n",
    "plt.ion()\n",
    "#import initial_ml as iml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d84ea8-40b0-47ff-9a54-b5eaec11a5ad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_directory = '../../data/HNSCC'\n",
    "nii_directory = '../../data/HNSCC/HNSCC_Nii_v3'\n",
    "resample_directory = '../../data/HNSCC/HNSCC_Nii_resample_222'\n",
    "graph_directory = '../../data/HNSCC/graph_staging'\n",
    "patch_directory = '../../data/HNSCC/HNSCC_Nii_222_50_50_60_Crop'\n",
    "location_pickle = '../../data/HNSCC/HNSCC_Nii_222_50_50_60_Crop/locations.pkl'\n",
    "\n",
    "patients_to_drop = [\n",
    "    'HNSCC-01-0228',\n",
    "    'HNSCC-01-0253',\n",
    "    'HNSCC-01-0358',\n",
    "    'HNSCC-01-0464',\n",
    "]\n",
    "data_path = Path(data_directory)\n",
    "nii_path = Path(nii_directory)\n",
    "resample_path = Path(resample_directory)\n",
    "patch_path = Path(patch_directory)\n",
    "pickle_path = Path(location_pickle)\n",
    "resample_path.mkdir(exist_ok=True, parents=True)\n",
    "patch_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ca491-a496-49b0-be48-4629d7c6f0b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get patients that at least have a GTVp mask in their directory\n",
    "filled_dirs = [p for p in patient_dirs if np.any(['gtv' in f.lower() for f in glob.glob(f\"{p}/*.nii*\")])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7b62a-c37f-4868-affe-69f36bb1d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary of patients and available image files\n",
    "\n",
    "gtvp_file_names = ['gtv.nii',\n",
    "                   'gtvp.nii',\n",
    "                   'gtv.nii',\n",
    "                   'gtv2.nii',\n",
    "                   'Primary-GTV.nii',\n",
    "                   'GTV1.nii',\n",
    "                   'gtv-primary',\n",
    "                   'gtv-prechemo',\n",
    "                   'gtv-postchemo',\n",
    "                   'gtv-bot',\n",
    "                   'GTV-Pre-CTH.nii',\n",
    "                   'GTVTumorPre.nii',\n",
    "                   'Pre-chemo-GTV',\n",
    "                   'GTV-Tumor',\n",
    "                   'GTV-T',\n",
    "                   'pre-chemo-GTV',\n",
    "                  ]\n",
    "                   \n",
    "gtvn_file_names = ['GTVn', \n",
    "                   'GTV-Nodes',\n",
    "                   'GTV-NODES',\n",
    "                   'GTV-node',\n",
    "                   'Node-GTV',\n",
    "                   'gtv-node',\n",
    "                   'gtv-nodes',\n",
    "                   'Nodal-GTV',\n",
    "                   'nodal-gtv',\n",
    "                   'GTV-LN',\n",
    "                   'node-GTV',\n",
    "                   'GTV-LT-node',\n",
    "                   'GTV-Lt-nodes',\n",
    "                   'GTV-Rt-Nodes',\n",
    "                   'gtv-ln',\n",
    "                   'L-LN-GTV',\n",
    "                   'GTVNodesPre.nii',\n",
    "                   'GTV-N',\n",
    "                  ]\n",
    "checks = ['GTV',\n",
    "          'gtv',\n",
    "          #'nod',\n",
    "          #'Nod',\n",
    "          #'NOD',\n",
    "          #'LN',\n",
    "         ]\n",
    "                   \n",
    "patient_dict = {p.split('\\\\')[-1]: [nii for nii in os.listdir(p) \n",
    "                                    if ('gtv' in nii.lower() or 'image' in nii) \n",
    "                                    and 'ptv' not in nii.lower() \n",
    "                                    and 'ctv' not in nii.lower()\n",
    "                                    and 'expanded' not in nii.lower()\n",
    "                                   ] \n",
    "                for p in filled_dirs\n",
    "                if int(p.split('\\\\')[-1].split('-')[-1].split('_')[0]) > 215\n",
    "                and p.split('\\\\')[-1].replace('.nii.gz','') not in patients_to_drop\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c483a5b7-f6ca-4db0-9026-9632703f4c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for p in patient_dict:\n",
    "    print('+++++++++++++++')\n",
    "    print(p)\n",
    "    for mask in patient_dict[p]:\n",
    "        print(f'    {mask}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9e473-cedb-4e9c-a5ce-d89e40d811cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = 'HNSCC-01-0272_00'\n",
    "masks = {}\n",
    "struct_image = sitk.ReadImage(os.path.join(resample_directory, patient, patient_dict[patient][0]))\n",
    "for i, m in enumerate(patient_dict[patient]):\n",
    "    if 'image' in m: continue\n",
    "    masks[m.split('.')[0]] = sitk.ReadImage(os.path.join(resample_directory, patient, m))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b26e0-ff41-4245-a063-600d650acbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitk.Show(struct_image)\n",
    "sitk.Show(masks['mask_GTVp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f25b3-ce33-4ffb-a1cb-c59e932bcf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = {}\n",
    "for m in masks:\n",
    "    patches[m] = np.where(sitk.GetArrayFromImage(masks[m])>0, sitk.GetArrayFromImage(struct_image), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151ddd3-2fb3-49b0-88b8-490f4856ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in patient_dict:\n",
    "    save_dir = os.path.join(patch_directory, p)\n",
    "    if not os.path.exists(save_dir): \n",
    "        os.makedirs(save_dir) \n",
    "    struct = sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(resample_directory, p, patient_dict[p][0])))\n",
    "    for i, m in enumerate(patient_dict[p]):\n",
    "        if 'image' in m: continue\n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(resample_directory, p, m)))\n",
    "        np.save(os.path.join(save_dir, m.replace('mask_','').split('.')[0]), np.where(mask>0, struct, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d8b2e-ebff-43b6-9032-ae14d1f52306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patient = 'HNSCC-01-0272_00'\n",
    "masks = {}\n",
    "struct_image = sitk.ReadImage(os.path.join(nii_directory, patient, patient_dict[patient][0]))\n",
    "for i, m in enumerate(patient_dict[patient]):\n",
    "    if 'image' in m: continue\n",
    "    masks[m.split('.')[0]] = sitk.ReadImage(os.path.join(nii_directory, patient, m))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164df831-4c27-4902-a246-b9ab5268aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in resample_path.glob('*'):\n",
    "    print(p.as_posix().split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390f214-1e15-46d8-8aac-a785c1c7bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = {}\n",
    "for p in resample_path.glob('*'):\n",
    "    p_str = p.as_posix().split('/')[-1]\n",
    "    if '0286' in p_str: continue\n",
    "    for m in p.glob('*.nii.gz'):\n",
    "        if 'image' in str(m): continue\n",
    "        m_str = m.as_posix().split('/')[-1].replace('.nii.gz','').replace('mask_', '')\n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(m))\n",
    "        shapes[f'{p_str}_{m_str}'] = np.nonzero(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e6670-185d-406d-9ca9-28d7b41f7474",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_size = []\n",
    "for s in shapes:\n",
    "    print(s)\n",
    "    \n",
    "    try:\n",
    "        x = np.max(shapes[s][0]) - np.min(shapes[s][0])\n",
    "        y = np.max(shapes[s][1]) - np.min(shapes[s][1])\n",
    "        z = np.max(shapes[s][2]) - np.min(shapes[s][2])\n",
    "        #shape_size[s] = [x, y, z]\n",
    "        shape_size.append([x, y, z])\n",
    "    except:\n",
    "        patients_to_drop.append(s)\n",
    "shape_size = np.array(shape_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5864e0a-f492-4343-ae3b-dc631476d33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(shape_size[:,0]))\n",
    "print(np.max(shape_size[:,1]))\n",
    "print(np.max(shape_size[:,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9571555-1755-4e89-85bf-1a5ecb27a2c7",
   "metadata": {},
   "source": [
    "## Resampling code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31493916-2d35-478b-879a-dd0c2d0c52bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler = sitk.ResampleImageFilter()\n",
    "resampler.SetOutputDirection([1, 0, 0, 0, 1, 0, 0, 0, 1])\n",
    "resampling = [2,2,2]\n",
    "resampler.SetOutputSpacing(resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c79337-2486-4f18-a47a-58c5a996d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bouding_boxes(ct, pt):\n",
    "    \"\"\"\n",
    "    Get the bounding boxes of the CT and PT images.\n",
    "    This works since all images have the same direction\n",
    "    \"\"\"\n",
    "\n",
    "    ct_origin = np.array(ct.GetOrigin())\n",
    "    pt_origin = np.array(pt.GetOrigin())\n",
    "\n",
    "    ct_position_max = ct_origin + np.array(ct.GetSize()) * np.array(\n",
    "        ct.GetSpacing())\n",
    "    pt_position_max = pt_origin + np.array(pt.GetSize()) * np.array(\n",
    "        pt.GetSpacing())\n",
    "    return np.concatenate(\n",
    "        [\n",
    "            np.maximum(ct_origin, pt_origin),\n",
    "            np.minimum(ct_position_max, pt_position_max),\n",
    "        ],\n",
    "        axis=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b210e844-26bd-4118-a32e-f010ed083730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_one_patient(p):\n",
    "    pat_str = p.as_posix().split('/')[-1]\n",
    "    patient_resample_path = resample_path.joinpath(pat_str)\n",
    "    patient_resample_path.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    ct = sitk.ReadImage(p.joinpath('image.nii.gz'))\n",
    "    #label = sitk.ReadImage(os.path.join(savePath, p, 'mask_GTVp.nii.gz'))\n",
    "    bb = get_bouding_boxes(ct, ct)\n",
    "    size = np.round((bb[3:] - bb[:3]) / resampling).astype(int)\n",
    "    resampler.SetOutputOrigin(bb[:3])\n",
    "    resampler.SetSize([int(k) for k in size])  # sitk is so stupid\n",
    "    resampler.SetInterpolator(sitk.sitkBSpline)\n",
    "    ct = resampler.Execute(ct)\n",
    "    sitk.WriteImage(ct, patient_resample_path.joinpath('image.nii.gz'))\n",
    "    resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    for m in p.glob('*.nii.gz'):\n",
    "        if 'image' in str(m): continue\n",
    "        label = sitk.ReadImage(m)\n",
    "        label = resampler.Execute(label)\n",
    "        sitk.WriteImage(label, patient_resample_path.joinpath(str(m).split('\\\\')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928cd7db-3734-4c28-8564-109b8834baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pat in tqdm(nii_path.glob('*')):\n",
    "    pat_str = pat.as_posix().split('/')[-1]\n",
    "    if pat_str in patients_to_drop: continue   \n",
    "    resample_one_patient(pat)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d4a745-91ab-458d-8dbb-cf5c6f6ea9e5",
   "metadata": {},
   "source": [
    "## 4. Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c22535f-9c4c-4325-8cf3-13ce8a909ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid(mask, p):\n",
    "\n",
    "    stats = sitk.LabelShapeStatisticsImageFilter()\n",
    "    stats.Execute(mask)\n",
    "    try:\n",
    "        centroid_coords = stats.GetCentroid(1)\n",
    "    except:\n",
    "        print(f'Something is wrong with centroid calculation for patient: {p}')\n",
    "    centroid_idx = mask.TransformPhysicalPointToIndex(centroid_coords)\n",
    "\n",
    "    return np.asarray(centroid_idx, dtype=np.float64), np.asarray(centroid_coords, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c89b09-c020-461e-ab3e-2ec025cdd351",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_path = Path('../../data/HNSCC/HNSCC_Nii_222_50_50_60_Crop_v2')\n",
    "crop_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5c293-b044-400c-913c-8c2653f4e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_range(min_d, max_d, d, size_d, p):\n",
    "    min_pad = 0\n",
    "    max_pad = 0\n",
    "    if min_d<0:\n",
    "        min_pad = abs(min_d)\n",
    "        min_d = 0\n",
    "        #max_d = min_d + d\n",
    "        #if max_d - size_d > 0:\n",
    "        #    max_pad = max_d-size_d\n",
    "            \n",
    "        #assert (max_d<size_d), f\"Cannot extract the patch with the shape {size_d} from the image with the shape {d} for patient {p}.\"\n",
    "    \n",
    "    if max_d>d:\n",
    "        max_pad = max_d - d\n",
    "        max_d = d\n",
    "        #min_d = max_d - size_d\n",
    "        #if min_d < 0:\n",
    "        #    min_pad = abs(min_d)\n",
    "            \n",
    "        #assert (min_d>0), f\"Cannot extract the patch with the shape {size_d} from the image with the shape {d} for patient {p}.\"\n",
    "\n",
    "    return min_d, max_d, int(min_pad), int(max_pad)\n",
    "patients_to_retry = [\n",
    "    'HNSCC-01-0225',\n",
    "    'HNSCC-01-0259',\n",
    "    'HNSCC-01-0272',\n",
    "    'HNSCC-01-0434',\n",
    "]\n",
    "physical_locations = {}\n",
    "for p_dir in tqdm(resample_path.glob('*')):\n",
    "    p_str = p_dir.as_posix().split('/')[-1]\n",
    "    #if p_str not in patients_to_retry: continue\n",
    "    #try:\n",
    "    if p_str in patients_to_drop:\n",
    "        print('skip ', p_str)\n",
    "        continue\n",
    "    patient_crop_path = crop_path.joinpath(p_str)\n",
    "    patient_crop_path.mkdir(exist_ok=True, parents=True)\n",
    "    physical_locations[p_str] = {}\n",
    "    patch_size = np.array([50,50,60])\n",
    "    for m in p_dir.glob('*.nii.gz'):\n",
    "        print('-----------------')\n",
    "        m_str = m.as_posix().split('/')[-1]\n",
    "        if 'image' in m_str: continue\n",
    "        #try:\n",
    "        image = sitk.ReadImage(p_dir.joinpath('image.nii.gz'))\n",
    "        mask = sitk.ReadImage(m)\n",
    "        #crop the image to patch_size around the tumor center\n",
    "        tumour_center, center_location = find_centroid(mask, p_str) # center of GTV\n",
    "        size = patch_size\n",
    "        min_coords = np.floor(tumour_center - size / 2).astype(np.int64)\n",
    "        max_coords = np.floor(tumour_center + size / 2).astype(np.int64)\n",
    "        min_x, min_y, min_z = min_coords\n",
    "        max_x, max_y, max_z = max_coords\n",
    "        (img_x, img_y, img_z)=image.GetSize()\n",
    "        min_x, max_x, min_pad_x, max_pad_x = tune_range(min_x, max_x, img_x, size[0], p_str) \n",
    "        min_y, max_y, min_pad_y, max_pad_y = tune_range(min_y, max_y, img_y, size[1], p_str) \n",
    "        min_z, max_z, min_pad_z, max_pad_z = tune_range(min_z, max_z, img_z, size[2], p_str) \n",
    "\n",
    "        min_pad = int(max([min_pad_x, min_pad_y, min_pad_z]))\n",
    "        max_pad = int(max([max_pad_x, max_pad_y, max_pad_z]))\n",
    "        lpad = list([min_pad_x, min_pad_y, min_pad_z])\n",
    "        upad = list([max_pad_x, max_pad_y, max_pad_z])\n",
    "        #print(m_str)\n",
    "        #print(lpad)\n",
    "        #print(upad)\n",
    "        print(image.GetSize())\n",
    "        print(min_coords, max_coords)\n",
    "        print(min_pad, max_pad)\n",
    "        image = image[min_x:max_x, min_y:max_y, min_z:max_z]\n",
    "        # window image intensities to [-500, 1000] HU range\n",
    "        image = sitk.Clamp(image, sitk.sitkFloat32, -500, 500)\n",
    "        mask = mask[min_x:max_x, min_y:max_y, min_z:max_z]\n",
    "        print(image.GetSize())\n",
    "        image = sitk.ConstantPad(image, lpad, upad, 0.0)\n",
    "        mask = sitk.ConstantPad(mask, lpad, upad, 0.0)\n",
    "        print(image.GetSize())\n",
    "        sitk.WriteImage(image, patient_crop_path.joinpath(f\"image_{m_str.replace('Struct_','')}\"))\n",
    "        sitk.WriteImage(mask, patient_crop_path.joinpath(m_str))\n",
    "        physical_locations[p_str][m_str.replace('Struct_','').replace('.nii.gz','')] = center_location\n",
    "        del(image)\n",
    "        del(mask)\n",
    "        #except:\n",
    "        #    print(m)\n",
    "        #    raise Exception('something went wrong...')\n",
    "    \n",
    "    #except:\n",
    "    #    print(p_str)\n",
    "        \n",
    "with open(crop_path.joinpath('locations.pkl'), 'wb') as f:\n",
    "    pickle.dump(physical_locations, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4975209-f0c5-45d6-9cc1-48e02412981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = sitk.ReadImage(patch_path.joinpath('HNSCC-01-0216/image_GTVp.nii.gz'))\n",
    "test_struct = sitk.ReadImage(patch_path.joinpath('HNSCC-01-0216/Struct_GTVp.nii.gz'))\n",
    "test_norm = sitk.NormalizeImageFilter()\n",
    "test_image_norm = test_norm.Execute(test_image)\n",
    "test_img_array = sitk.GetArrayFromImage(test_image_norm)\n",
    "test_struct_array = sitk.GetArrayFromImage(test_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9be36a-6f04-4876-a11b-52abb202bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.stack((test_img_array, test_struct_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f2582c-2502-4088-9b8d-cdec77538080",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_patch_paths = patch_path.glob('*/')\n",
    "tumor_locations = pd.read_pickle(pickle_path)\n",
    "centered_locations = {}\n",
    "for pat in patient_patch_paths:\n",
    "    pat_str = pat.as_posix().split('/')[-1]\n",
    "    centered_locations[pat_str] = {}\n",
    "    n_tumors = len(tumor_locations[pat_str])\n",
    "    translation_factor = np.array([0, 0, 0])\n",
    "    if n_tumors == 1:\n",
    "        centered_locations[pat_str]['GTVp'] = np.array([0., 0., 0.])\n",
    "        continue\n",
    "    else:\n",
    "        if 'GTVp' in tumor_locations[pat_str].keys():\n",
    "            translation_factor = tumor_locations[pat_str]['GTVp']\n",
    "        else:\n",
    "            array_locs = np.array([val for val in tumor_locations[pat_str].values()])\n",
    "            origin_idx = np.where(array_locs == np.max(array_locs, axis=0)[2])[0][0]\n",
    "            translation_factor = array_locs[origin_idx]\n",
    "    for tumor in tumor_locations[pat_str]:\n",
    "        centered_locations[pat_str][tumor.replace('.nii.gz','')] = tumor_locations[pat_str][tumor] - translation_factor\n",
    "\n",
    "print(centered_locations)\n",
    "                \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ab193-bbc1-4f31-a5d2-d75de5c6feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = sqrt(x^2 + y^2 + z^2)\n",
    "# theta = atan2 ( sqrt(x^2+y^2) / z) accounting for different quadrants (make sure to use atan2 not atan)\n",
    "# phi = atan2 (y/x) \n",
    "\n",
    "spherical_locations = {}\n",
    "for pat, locs in centered_locations.items():\n",
    "    spherical_locations[pat] = {}\n",
    "    for gtv, l in locs.items():\n",
    "        if np.all([not(l[0]), not(l[1]), not(l[2])]): \n",
    "            print(f'origin: {pat}, {gtv}')\n",
    "            spherical_locations[pat][gtv] = np.array([0.,0.,0.])\n",
    "            continue\n",
    "        radius = np.sqrt(l[0]**2+l[1]**2+l[2]**2)\n",
    "        theta = np.arctan2(np.sqrt(l[0]**2+l[1]**2), l[2])\n",
    "        phi = np.arctan2(l[1], l[0])\n",
    "        if phi < 0:\n",
    "            phi = phi + 2*np.pi\n",
    "        spherical_locations[pat][gtv] = np.array([radius, theta, phi])\n",
    "\n",
    "print(spherical_locations)\n",
    "pat_259 = spherical_locations['HNSCC-01-0259']\n",
    "#with open(crop_path.joinpath('sph_locations.pkl'), 'wb') as f:\n",
    "#    pickle.dump(spherical_locations, f)\n",
    "#    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e5e967-7d68-4b04-bcfc-78149a7e9fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(crop_path.joinpath('sph_locations.csv'), 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for pat, gtv in spherical_locations.items():\n",
    "        for gtv_str, coords in gtv.items():\n",
    "            writer.writerow([pat, gtv_str, coords])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7647a99-63e4-4cd6-875e-dd84a89632bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_phi_rtheta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0109d1df-7a29-409a-96f4-0992a4039c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_259_r_sorted = {k: v for k, v in sorted(pat_259.items(), key=lambda item: item[1][0])}\n",
    "pat_259_phi_sorted = {k: v for k, v in sorted(pat_259.items(), key=lambda item: item[1][2])}\n",
    "pat_259_theta_sorted = {k: v for k, v in sorted(pat_259.items(), key=lambda item: item[1][1])}\n",
    "groups_phi = {}\n",
    "groups_phi_gtv = {}\n",
    "reference = list(pat_259_phi_sorted.values())[1][2] \n",
    "g_num = 'phi_1'\n",
    "groups_phi[g_num] = []\n",
    "for gtv, l in pat_259_phi_sorted.items():\n",
    "    if 0. in l: \n",
    "        groups_phi_gtv[gtv] = 'phi_0'\n",
    "        continue\n",
    "    phi_diff = l[2] - reference\n",
    "    print(phi_diff)\n",
    "    if np.abs(phi_diff) < 0.4:\n",
    "        groups_phi[g_num].append(gtv)\n",
    "        groups_phi_gtv[gtv] = g_num\n",
    "    else:\n",
    "        g_num = f\"phi_{int(g_num.split('_')[-1])+1}\"\n",
    "        groups_phi[g_num] = []\n",
    "        groups_phi[g_num].append(gtv)\n",
    "        groups_phi_gtv[gtv] = g_num\n",
    "        reference = l[2]\n",
    "for g in groups_phi:\n",
    "    groups_phi[g] = [k for k in sorted(groups_phi[g], key=lambda gtv: pat_259[gtv][0])] \n",
    "    \n",
    "groups_theta = {}\n",
    "groups_theta_gtv = {}\n",
    "reference = list(pat_259_theta_sorted.values())[1][1] \n",
    "g_num = 'theta_1'\n",
    "groups_theta[g_num] = []\n",
    "print(pat_259_theta_sorted)\n",
    "for gtv, l in pat_259_theta_sorted.items():\n",
    "    if 0. in l:\n",
    "        groups_theta_gtv[gtv] = 'theta_0'\n",
    "        continue\n",
    "    theta_diff = l[1] - reference\n",
    "    print(gtv)\n",
    "    print(theta_diff)\n",
    "    if np.abs(theta_diff) < 0.3:\n",
    "        groups_theta[g_num].append(gtv)\n",
    "        groups_theta_gtv[gtv] = g_num\n",
    "    else:\n",
    "        g_num = f\"theta_{int(g_num.split('_')[-1])+1}\"\n",
    "        groups_theta[g_num] = []\n",
    "        groups_theta[g_num].append(gtv)\n",
    "        groups_theta_gtv[gtv] = g_num\n",
    "        reference = l[1]\n",
    "for g in groups_theta:\n",
    "    groups_theta[g] = [k for k in sorted(groups_theta[g], key=lambda gtv: pat_259[gtv][0])]\n",
    "print(groups_phi)\n",
    "print(groups_theta)\n",
    "print(groups_phi_gtv)\n",
    "print(groups_theta_gtv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d814d1-618d-400d-b4b8-7c60802c8c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups_phi = pd.DataFrame(groups_phi_gtv.values(), index=groups_phi_gtv.keys(), columns=['phi_group'])\n",
    "df_groups_theta = pd.DataFrame(groups_theta_gtv.values(), index=groups_theta_gtv.keys(), columns=['theta_group'])\n",
    "print(df_groups_phi)\n",
    "print(df_groups_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20365b6a-a35a-4222-b8a7-ca1473c81e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_259 = spherical_locations['HNSCC-01-0259']\n",
    "#plt.ion()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "points = []\n",
    "label = []\n",
    "for gtv in pat_259:\n",
    "    r = pat_259[gtv][0]\n",
    "    theta = pat_259[gtv][1]\n",
    "    phi = pat_259[gtv][2]\n",
    "    x = r * np.sin(theta) * np.cos(phi)\n",
    "    y = r * np.sin(theta) * np.sin(phi)\n",
    "    z = r * np.cos(theta)\n",
    "    points.append([x, y, z])\n",
    "    label.append(gtv)\n",
    "\n",
    "points = np.array(points)\n",
    "ax.scatter(points[:,0], points[:,1], points[:,2])\n",
    "for i, l in enumerate(label):\n",
    "    ax.text(points[i, 0], points[i, 1], points[i, 2], l)\n",
    "plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466e5109-5abc-4ffe-a98b-d62ea5028d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "hier_clust = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
    "hier_clust = hier_clust.fit(df_259[['x', 'y', 'z']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d349d-520f-46c9-84da-31fd5d5cbe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "    return linkage_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325ffc0c-b7da-49c0-b2ce-4473e7f45ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker = plot_dendrogram(hier_clust, show_leaf_counts=False, labels=df_259.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed67351-0b43-4c60-bc72-f3abbaa2acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hier_clust.children_)\n",
    "print(hier_clust.distances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b36f36-6d67-48cc-9332-e28abe7a375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df_259)\n",
    "def create_node_tree(children):\n",
    "    def recursive_walk(child):\n",
    "        node = []\n",
    "        for ch in child:\n",
    "            if ch < N:\n",
    "                node.append(df_259.index[ch])\n",
    "            else:\n",
    "                node.append(recursive_walk(children[ch-N]))\n",
    "\n",
    "        return node\n",
    "\n",
    "    all_nodes = []\n",
    "    for idx in children:\n",
    "        all_nodes.append(recursive_walk(idx))\n",
    "    return all_nodes\n",
    "\n",
    "test = create_node_tree(hier_clust.children_)\n",
    "print(test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf288dd-8420-4df9-8ffc-46fd2f5757a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217821e-eadd-4435-9b1a-3fed00deaf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = test[-1]\n",
    "connections[1]\n",
    "#df_259.loc[np.ndarray.flatten(np.array(connections[1][1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5355221-7679-4b48-ac83-82f1c6d9d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb436c8-9e6a-49a6-b40f-770238ea2019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edges(tree):\n",
    "    dict_edges = {}\n",
    "    \n",
    "    def recursive_walk(sub_tree, branch):\n",
    "        for i, sub in enumerate(sub_tree):\n",
    "            sub_branch = branch + str(i)\n",
    "            if len(sub) == 2:\n",
    "                dict_edges[sub_branch] = sub\n",
    "                recursive_walk(sub, sub_branch)\n",
    "            else:\n",
    "                dict_edges[sub_branch] = sub\n",
    "\n",
    "    for i, leaf in enumerate(tree):\n",
    "        dict_edges[str(i)] = leaf\n",
    "        recursive_walk(leaf, str(i))\n",
    "    return dict_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e9518-b8b6-4418-9f55-47270218761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminals = []\n",
    "test_edges = create_edges(connections)\n",
    "for branch in test_edges:\n",
    "    if len(test_edges[branch]) == 2: continue\n",
    "    else:\n",
    "        terminals.append(branch)\n",
    "terminals_map = {v: k for k, v in test_edges.items() if k in terminals}\n",
    "edges_map = {str(v): k for k, v in test_edges.items()}\n",
    "print(terminals)\n",
    "print(test_edges)\n",
    "print(terminals_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36cd3c-2dbd-4df1-a2c8-d77d9cea36c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edges_remap = {}\n",
    "for k, v in test_edges.items():\n",
    "    test_edges_remap[k] = []\n",
    "    if k in terminals:\n",
    "        test_edges_remap[k].append(test_edges[k])\n",
    "    else:\n",
    "        for arr in v:\n",
    "            test_edges_remap[k].append(edges_map[str(arr)])\n",
    "#test_edges_remap = {k: v for k, v in sorted(test_edges_remap.items(), key=lambda item: len(item[0]), reverse=True)}\n",
    "test_edges_remap = {k: v for k, v in sorted(test_edges_remap.items(), key=lambda item: len(item[0]))}\n",
    "test_edges_remap = {'p': ['0', '1'], **test_edges_remap}\n",
    "#test_edges_remap = {**test_edges_remap, 'p': [0,1]}\n",
    "test_edges = {k: v for k, v in sorted(test_edges.items(), key=lambda item: len(item[0]))}\n",
    "test_edges_remap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f459751-9dfd-4f92-a81e-3e66188dfddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "skip_to_primary = []\n",
    "def get_tree(branch):\n",
    "    def recursive_walk(sub_branch):\n",
    "        global skip_to_primary\n",
    "        compare = []\n",
    "        sub_branch_leaves = test_edges_remap[sub_branch]\n",
    "        for leaf in sub_branch_leaves:\n",
    "            print(f\"        sub leaf: {leaf} for branch: {sub_branch}\")\n",
    "            if leaf in test_edges_remap.keys():\n",
    "                print(f\"    entering recursion for {leaf} in {sub_branch}\")\n",
    "                compare.append(recursive_walk(leaf))\n",
    "            else:\n",
    "                compare.append(leaf)\n",
    "\n",
    "        if np.all([isinstance(c, str) for c in compare]):\n",
    "            print(compare)\n",
    "            df_c = df_259.loc[compare]\n",
    "            if len(df_c) == 1:\n",
    "                print(f\"    exiting recursion for {sub_branch}\")\n",
    "                return df_c.index[0]\n",
    "            df_c.sort_values(['r'], inplace=True)\n",
    "            print(f\"adding edge {[df_c.index[0], df_c.index[1]]}\")\n",
    "            edges.append([df_c.index[0], df_c.index[1]])\n",
    "            print(f\"    exiting recursion for {sub_branch}\")\n",
    "            return list(df_c.index)\n",
    "            \n",
    "        to_return = []\n",
    "        for i, leaf in enumerate(compare):\n",
    "            if isinstance(leaf, str):\n",
    "                compare[i] = [leaf]\n",
    "            \n",
    "        df_0 = df_259.loc[compare[0]]\n",
    "        df_0.sort_values('r', inplace=True)\n",
    "        df_1 = df_259.loc[compare[1]]\n",
    "        df_1.sort_values('r', inplace=True)\n",
    "\n",
    "        if len(df_0.index) == 2:\n",
    "            if [df_0.index[0], df_0.index[1]] not in edges:\n",
    "                edges.append([df_0.index[0], df_0.index[1]])\n",
    "\n",
    "        if len(df_1.index) == 2:\n",
    "            if [df_1.index[0], df_1.index[1]] not in edges:\n",
    "                print(f\"adding edge: {[df_1.index[0], df_1.index[1]]}\")\n",
    "                edges.append([df_1.index[0], df_1.index[1]])\n",
    "                \n",
    "        if df_1['theta_group'].nunique(0) == 1:\n",
    "            if df_0.loc[df_0.index[-1]]['r'] < df_1.loc[df_1.index[0]]['r']:\n",
    "                print(f\"adding edge: {[df_0.index[-1], df_1.index[0]]}\")\n",
    "                edges.append([df_0.index[-1], df_1.index[0]])\n",
    "            elif df_1.loc[df_1.index[-1]]['r'] < df_0.loc[df_0.index[0]]['r']:\n",
    "                print(f\"adding edge: {[df_1.index[-1], df_0.index[0]]}\")\n",
    "                edges.append([df_1.index[-1], df_0.index[0]])\n",
    "        elif df_0['theta_group'].nunique(0) == 1:\n",
    "            if df_0.loc[df_0.index[-1]]['r'] < df_1.loc[df_1.index[0]]['r']:\n",
    "                print(f\"adding edge: {[df_0.index[-1], df_1.index[0]]}\")\n",
    "                edges.append([df_0.index[-1], df_1.index[0]])\n",
    "            elif df_1.loc[df_1.index[-1]]['r'] < df_0.loc[df_0.index[0]]['r']:\n",
    "                print(f\"adding edge: {[df_1.index[-1], df_0.index[0]]}\")\n",
    "                edges.append([df_1.index[-1], df_0.index[0]])\n",
    "                \n",
    "        if np.max(df_0['r']) < np.max(df_1['r']):\n",
    "            for leaf in df_1.index:\n",
    "                if df_1['phi_group'].nunique(0) == 1 and df_1['theta_group'].nunique(0) > 1:\n",
    "                    if [df_0.index[-1], leaf] in edges: continue\n",
    "                    print(f\"adding edge: {[df_0.index[-1], leaf]}\")\n",
    "                    edges.append([df_0.index[-1], leaf]) \n",
    "        else:\n",
    "            for leaf in df_0.index:\n",
    "                if df_0['phi_group'].nunique(0) == 1 and df_0['theta_group'].nunique(0) > 1:\n",
    "                    if [df_1.index[-1], leaf] in edges: continue\n",
    "                    print(f\"adding edge: {[df_1.index[-1], leaf]}\")\n",
    "                    edges.append([df_1.index[-1], leaf]) \n",
    "\n",
    "        \n",
    "        df_sub_branch = df_259.loc[compare[0] + compare[1]]\n",
    "        df_sub_branch.sort_values(['phi_group', 'r'], inplace=True)\n",
    "\n",
    "        if df_sub_branch['phi_group'].nunique(0) >  1:\n",
    "            phi_counts = df_sub_branch.value_counts('phi_group')\n",
    "            group_to_send = phi_counts[phi_counts == phi_counts.min()].index[0]\n",
    "            skip_to_primary += list(df_sub_branch[df_sub_branch['phi_group']==group_to_send].index)\n",
    "            \n",
    "            \n",
    "        return list(df_sub_branch.index[:2])\n",
    "        \n",
    "            \n",
    "                \n",
    "\n",
    "    to_compare = []\n",
    "    leaves = test_edges_remap[branch]\n",
    "    for leaf in leaves:\n",
    "        print(f\"leaf: {leaf}\")\n",
    "        if leaf in test_edges_remap.keys():\n",
    "            print(f\"    entering recursion for {leaf}\")\n",
    "            to_compare.append(recursive_walk(leaf))\n",
    "        else:\n",
    "            to_compare.append([leaf])\n",
    "\n",
    "    print(f\"done with recursion, for branch: {branch}\")\n",
    "    last_compare = []\n",
    "    for i, leaf in enumerate(to_compare):\n",
    "        if isinstance(leaf, str):\n",
    "            to_compare[i] = [leaf]\n",
    "    df_0 = df_259.loc[to_compare[0]]\n",
    "    df_0.sort_values('r', inplace=True)\n",
    "    df_1 = df_259.loc[to_compare[1]]\n",
    "    df_1.sort_values('r', inplace=True)\n",
    "\n",
    "    if df_1['theta_group'].nunique(0) == 1:\n",
    "        if df_0.loc[df_0.index[-1]]['r'] < df_1.loc[df_1.index[0]]['r']:\n",
    "            print(f\"adding edge: {[df_0.index[-1], df_1.index[0]]}\")\n",
    "            edges.append([df_0.index[-1], df_1.index[0]])\n",
    "        elif df_1.loc[df_1.index[-1]]['r'] < df_0.loc[df_0.index[0]]['r']:\n",
    "            print(f\"adding edge: {[df_1.index[-1], df_0.index[0]]}\")\n",
    "            edges.append([df_1.index[-1], df_0.index[0]])\n",
    "    elif df_0['theta_group'].nunique(0) == 1:\n",
    "        if df_0.loc[df_0.index[-1]]['r'] < df_1.loc[df_1.index[0]]['r']:\n",
    "            print(f\"adding edge: {[df_0.index[-1], df_1.index[0]]}\")\n",
    "            edges.append([df_0.index[-1], df_1.index[0]])\n",
    "        elif df_1.loc[df_1.index[-1]]['r'] < df_0.loc[df_0.index[0]]['r']:\n",
    "            print(f\"adding edge: {[df_1.index[-1], df_0.index[0]]}\")\n",
    "            edges.append([df_1.index[-1], df_0.index[0]])\n",
    "            \n",
    "    if np.max(df_0['r']) < np.max(df_1['r']):\n",
    "        for leaf in df_1.index:\n",
    "            if df_1['phi_group'].nunique(0) == 1 and df_1['theta_group'].nunique(0) > 1:\n",
    "                if [df_0.index[-1], leaf] in edges: continue\n",
    "                print(f\"adding edge: {[df_0.index[-1], leaf]}\")\n",
    "                edges.append([df_0.index[-1], leaf]) \n",
    "    else:\n",
    "        for leaf in df_0.index:\n",
    "            if df_0['phi_group'].nunique(0) == 1 and df_0['theta_group'].nunique(0) > 1:\n",
    "                if [df_1.index[-1], leaf] in edges: continue\n",
    "                print(f\"adding edge: {[df_1.index[-1], leaf]}\")\n",
    "                edges.append([df_1.index[-1], leaf]) \n",
    "    \n",
    "    df_branch = df_259.loc[to_compare[0] + to_compare[1]]\n",
    "    df_branch.sort_values('r', inplace=True)\n",
    "    return list(df_branch.index[:2])\n",
    "\n",
    "\n",
    "final_compare = []\n",
    "for leaf in test_edges_remap['p']:\n",
    "    final_compare.append(get_tree(leaf))\n",
    "print(f\"finished tree recursion, starting final comparisons\")\n",
    "last_edges = []\n",
    "for c in final_compare:\n",
    "    df_c = df_259.loc[c]\n",
    "    df_c.sort_values('r', inplace=True)\n",
    "    if df_c['phi_group'].nunique(0) == 1 and df_c['theta_group'].nunique(0) == 1:\n",
    "        last_edges += [df_c.index[0]]\n",
    "    else:\n",
    "        last_edges += list(df_c.index)\n",
    "\n",
    "for gtv in last_edges:\n",
    "    print(f\"adding edge: {[primary, gtv]}\")\n",
    "    edges.append([primary, gtv]) \n",
    "for gtv in skip_to_primary:\n",
    "    print(f\"adding edge: {[primary, gtv]}\")\n",
    "    edges.append([primary,gtv])\n",
    "print(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a5a14-1a78-4d34-a7b0-660863c92f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_259.value_counts('phi_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92552645-2e5a-49eb-be64-6fa545cbf1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = []\n",
    "test2 += list(test[test==test.min()].index)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7197d2c-65b6-4f2b-8b1b-c01d271be693",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainers = []\n",
    "for idx in range(5):\n",
    "    model.set_model()\n",
    "    model.set_callbacks(idx)\n",
    "    model.trainers.append(L.Trainer(\n",
    "                    max_epochs=model.config['n_epochs'],\n",
    "                    accelerator=\"auto\",\n",
    "                    devices=model.config['gpu_device'] if torch.cuda.is_available() else None,\n",
    "                    logger=[L.loggers.CSVLogger(save_dir=os.path.join(model.log_dir, f\"csvlog_fold_{idx}\")), L.loggers.TensorBoardLogger(save_dir=os.path.join(model.log_dir, f\"tb_fold_{idx}\"))],\n",
    "                    callbacks=model.callbacks,\n",
    "                    #check_val_every_n_epoch = 1,\n",
    "                    #auto_lr_find=True\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1838e28c-c287-429b-9c15-8b837895e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## w/o graph models\n",
    "model_directory = './logs/lightning_feat64_no_graph_weight9_real_dp3_11180_minmax_rot10_balance_newclinical_nolrfinder_nocensor_v36'\n",
    "fold_models = [\n",
    "    'model_m_epoch=46_val_loss=3.70_val_auc=0.89_val_m=0.86.ckpt',\n",
    "    'model_m_epoch=01_val_loss=4.82_val_auc=0.72_val_m=0.65.ckpt',\n",
    "    'model_m_epoch=52_val_loss=5.66_val_auc=0.88_val_m=0.81.ckpt',\n",
    "    'model_m_epoch=10_val_loss=1.05_val_auc=0.81_val_m=0.72.ckpt',\n",
    "    'model_m_epoch=30_val_loss=50.76_val_auc=0.68_val_m=0.71.ckpt',\n",
    "]\n",
    "## w/graph models\n",
    "#model_directory = './logs/lightning_feat64_with_graph_weight9_real_dp3_11180_minmax_rot10_balance_newclinical_nolrfinder_nocensor_v36'\n",
    "#fold_models = [\n",
    "#    'model_m_epoch=28_val_loss=1.80_val_auc=0.87_val_m=0.68.ckpt',\n",
    "#    'model_m_epoch=09_val_loss=0.42_val_auc=0.93_val_m=0.89.ckpt',\n",
    "#    'model_m_epoch=15_val_loss=0.80_val_auc=0.87_val_m=0.85.ckpt',\n",
    "#    'model_m_epoch=65_val_loss=0.36_val_auc=0.82_val_m=0.75.ckpt',\n",
    "#    'model_m_epoch=00_val_loss=2.60_val_auc=0.68_val_m=0.67.ckpt',\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da18460-d59e-4820-89ad-bd6ad57d44bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(5):\n",
    "    model_path = os.path.join(model_directory, f\"top_models_fold_{idx}\", fold_models[idx])\n",
    "    model.trainers[idx].validate(model.model, datamodule=model.data_module_cross_val[idx], ckpt_path=model_path)\n",
    "    model.trainers[idx].test(model.model, datamodule=model.data_module_cross_val[idx], ckpt_path=model_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu_v2",
   "language": "python",
   "name": "pytorch_gpu_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
