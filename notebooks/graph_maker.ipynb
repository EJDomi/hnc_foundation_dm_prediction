{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d5a20-757a-401b-b283-fa188c42be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib widget\n",
    "#%matplotlib ipympl\n",
    "\n",
    "#%reload_ext tensorboard\n",
    "#%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd98c0b-5e5c-4549-98e8-d604b8b111ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "from tqdm.auto import tqdm\n",
    "import pickle, subprocess\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import torch\n",
    "import sklearn\n",
    "import csv\n",
    "import gc\n",
    "\n",
    "from radiomics import featureextractor\n",
    "import radiomics\n",
    "\n",
    "import glob\n",
    "\n",
    "from hnc_project import data_prep as dp\n",
    "from hnc_project import myshow\n",
    "from hnc_project import graph_making as gm\n",
    "from hnc_project.pytorch import dataset_class as dc\n",
    "from hnc_project.pytorch.run_model_torch import RunModel\n",
    "#%matplotlib notebook\n",
    "%matplotlib widget\n",
    "plt.ion()\n",
    "#import initial_ml as iml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8e2fc6-966e-4a72-b809-349a7405e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '../../data/LIDC-IDRI'\n",
    "nii_directory = '../../data/LIDC-IDRI/Nii'\n",
    "resample_directory = '../../data/LIDC-IDRI/Nii_resample_111'\n",
    "graph_directory = '../../data/LIDC-IDRI/graph_staging'\n",
    "edge_directory = '../../data/HNSCC/edge_staging'\n",
    "patch_directory = '../../data/HNSCC/HNSCC_Nii_222_50_50_60_Crop_v2'\n",
    "location_pickle = '../../data/HNSCC/HNSCC_Nii_222_50_50_60_Crop_v2/locations.pkl'\n",
    "plot_directory = '../../data/HNSCC/plots'\n",
    "radiomics_directory = '../../data/HNSCC/radiomics_wavelets'\n",
    "\n",
    "data_path = Path(data_directory)\n",
    "nii_path = Path(nii_directory)\n",
    "resample_path = Path(resample_directory)\n",
    "patch_path = Path(patch_directory)\n",
    "location_pickle_path = Path(location_pickle)\n",
    "plot_path = Path(plot_directory)\n",
    "graph_path = Path(graph_directory)\n",
    "edge_path = Path(edge_directory)\n",
    "radiomics_path = Path(radiomics_directory)\n",
    "\n",
    "resample_path.mkdir(exist_ok=True, parents=True)\n",
    "patch_path.mkdir(exist_ok=True, parents=True)\n",
    "plot_path.mkdir(exist_ok=True, parents=True)\n",
    "graph_path.mkdir(exist_ok=True, parents=True)\n",
    "edge_path.mkdir(exist_ok=True, parents=True)\n",
    "radiomics_path.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6f191-9cf9-4f44-ae9d-240cc1943c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_patch_paths = patch_path.glob('*/')\n",
    "tumor_locations = pd.read_pickle(location_pickle_path)\n",
    "centered_locations = {}\n",
    "for pat in patient_patch_paths:\n",
    "    pat_str = pat.as_posix().split('/')[-1]\n",
    "    centered_locations[pat_str] = {}\n",
    "    n_tumors = len(tumor_locations[pat_str])\n",
    "    translation_factor = np.array([0, 0, 0])\n",
    "    if n_tumors == 1:\n",
    "        centered_locations[pat_str]['GTVp'] = np.array([0., 0., 0.])\n",
    "        continue\n",
    "    else:\n",
    "        if 'GTVp' in tumor_locations[pat_str].keys():\n",
    "            translation_factor = tumor_locations[pat_str]['GTVp']\n",
    "        else:\n",
    "            array_locs = np.array([val for val in tumor_locations[pat_str].values()])\n",
    "            origin_idx = np.where(array_locs == np.max(array_locs, axis=0)[2])[0][0]\n",
    "            translation_factor = array_locs[origin_idx]\n",
    "    for tumor in tumor_locations[pat_str]:\n",
    "        centered_locations[pat_str][tumor.replace('.nii.gz','')] = tumor_locations[pat_str][tumor] - translation_factor\n",
    "\n",
    "with open(edge_path.joinpath('centered_locations_010424.pkl'), 'wb') as f:\n",
    "    pickle.dump(centered_locations, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37780c10-f793-4a45-8b94-3cb151b3bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = sqrt(x^2 + y^2 + z^2)\n",
    "# theta = atan2 ( sqrt(x^2+y^2) / z) accounting for different quadrants (make sure to use atan2 not atan)\n",
    "# phi = atan2 (y/x) \n",
    "\n",
    "spherical_locations = {}\n",
    "for pat, locs in centered_locations.items():\n",
    "    spherical_locations[pat] = {}\n",
    "    for gtv, l in locs.items():\n",
    "        if np.all([not(l[0]), not(l[1]), not(l[2])]): \n",
    "            #print(f'origin: {pat}, {gtv}')\n",
    "            spherical_locations[pat][gtv] = np.array([0.,0.,0.])\n",
    "            continue\n",
    "        radius = np.sqrt(l[0]**2+l[1]**2+l[2]**2)\n",
    "        theta = np.arctan2(np.sqrt(l[0]**2+l[1]**2), l[2])\n",
    "        phi = np.arctan2(l[1], l[0])\n",
    "        if phi < 0 and abs(phi) > np.pi/2:\n",
    "            phi = phi + 2*np.pi\n",
    "        spherical_locations[pat][gtv] = np.array([radius, theta, phi])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a05b5-b44f-4f71-95fc-1b04623f8438",
   "metadata": {},
   "source": [
    "look into once starting training:\n",
    "Make the CTs into an object containing vertex objects that store position/volume information. Within this object you then loop through all nodes and find possible nearby connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15047284-db13-4109-b41b-b2e4b28d4a20",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_edges = {}\n",
    "for pat in spherical_locations.keys():\n",
    "    #if '0628' not in pat: continue\n",
    "    patient_plot_path = plot_path.joinpath(pat)\n",
    "    patient_plot_path.mkdir(exist_ok=True, parents=True)\n",
    "    print(f\"Processing patient: {pat}\")\n",
    "    pat_locs = spherical_locations[pat]\n",
    "    if len(pat_locs) == 1:\n",
    "        print(\"    one node, empty edge array\")\n",
    "        dict_edges[pat] = []\n",
    "        continue\n",
    "    df_pat, primary = gm.make_loc_df(pat_locs)\n",
    "    if len(pat_locs) == 2 and len(df_pat) == 1:\n",
    "        print(\"    two nodes, single edge entry\")\n",
    "        print(f\"edge: [{primary.index[0]}, {df_pat.index[0]}]\")\n",
    "        dict_edges[pat] = [[primary.index[0], df_pat.index[0]]]\n",
    "        continue\n",
    "    clust_model = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
    "    clust_model = clust_model.fit(df_pat[['x', 'y', 'z']])\n",
    "    node_tree = gm.create_node_tree(clust_model.children_, df_pat)\n",
    "    connections = gm.create_connection_tree(node_tree)\n",
    "    print(connections)\n",
    "    edges = gm.make_edges(connections, df_pat, primary.index[0])\n",
    "    dict_edges[pat] = edges\n",
    "    print(edges)\n",
    "    \n",
    "    #plt.ion()\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    points = []\n",
    "    label = []\n",
    "    for gtv in df_pat.index:\n",
    "        points.append([df_pat.loc[gtv]['x'], df_pat.loc[gtv]['y'], df_pat.loc[gtv]['z']])\n",
    "        label.append(gtv)\n",
    "    for gtv in primary.index:\n",
    "        points.append([primary.loc[gtv]['x'], primary.loc[gtv]['y'], primary.loc[gtv]['z']])\n",
    "        label.append(gtv)\n",
    "        \n",
    "    points = np.array(points)\n",
    "    ax.scatter(points[:,0], points[:,1], points[:,2])\n",
    "    for i, l in enumerate(label):\n",
    "        ax.text(points[i, 0], points[i, 1], points[i, 2], l)\n",
    "    \n",
    "    edge_points = []\n",
    "    for e in edges:\n",
    "        edge_points.append([points[label.index(e[0])], points[label.index(e[1])]])\n",
    "    \n",
    "    for e in edge_points:\n",
    "        ex_diff = e[1][0] - e[0][0]\n",
    "        ey_diff = e[1][1] - e[0][1]\n",
    "        ez_diff = e[1][2] - e[0][2]\n",
    "        ax.quiver(e[0][0], e[0][1], e[0][2], ex_diff, ey_diff, ez_diff, color='r')\n",
    "    plt.savefig(patient_plot_path.joinpath('connections_3D.pdf'))\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a85ca-bde1-4d2e-904d-5d8d2d354d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(edge_path.joinpath('edges_122823.pkl'), 'wb') as f:\n",
    "    pickle.dump(dict_edges, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600520ce-4e18-4ef7-9072-68e625b0bc0c",
   "metadata": {},
   "source": [
    "### Basic radiomic feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a9bd6-2bbc-4a5c-89d9-aac9fef5cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "radiomics.setVerbosity(20)\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "extractor.enableImageTypeByName('Wavelet')\n",
    "print(extractor.settings)\n",
    "print(extractor.enabledImagetypes)\n",
    "print(extractor.enabledFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195722a0-ca76-4c91-a87d-3e3a862f519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_patch_paths = patch_path.glob('*/')\n",
    "for pat in patient_patch_paths:\n",
    "    pat_str = pat.as_posix().split('/')[-1]\n",
    "    print(pat_str)\n",
    "\n",
    "    patches = pat.glob('image*.nii.gz')\n",
    "    features_to_keep = {}\n",
    "    for p in patches:\n",
    "        p_name = p.as_posix().split('_')[-1].replace('.nii.gz','')\n",
    "        print(f\"    {p_name}\")\n",
    "        image = p.as_posix()\n",
    "        mask = p.as_posix().replace('image', 'Struct')\n",
    "        features = extractor.execute(image, mask)\n",
    "        features_to_keep[p_name] = {key: value for key, value in features.items() if key.startswith('original')}\n",
    "        \n",
    "    with open(radiomics_path.joinpath(f\"features_{pat_str}.pkl\"), 'wb') as f:\n",
    "        pickle.dump(features_to_keep, f)        \n",
    "        f.close()\n",
    "      \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc12427-baae-45d5-9035-363999b57259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu_v2",
   "language": "python",
   "name": "pytorch_gpu_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
